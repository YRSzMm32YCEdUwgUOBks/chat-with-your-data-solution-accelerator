# Azure Search for storing the processed documents
AZURE_SEARCH_USE_SEMANTIC_SEARCH=False
AZURE_SEARCH_SEMANTIC_SEARCH_CONFIG=default
AZURE_SEARCH_TOP_K=5
AZURE_SEARCH_ENABLE_IN_DOMAIN=False
AZURE_SEARCH_FIELDS_ID=id
AZURE_SEARCH_CONTENT_COLUMN=content
AZURE_SEARCH_CONTENT_VECTOR_COLUMN=content_vector
AZURE_SEARCH_DIMENSIONS=1536
AZURE_SEARCH_FIELDS_TAG=tag
AZURE_SEARCH_FIELDS_METADATA=metadata
AZURE_SEARCH_FILENAME_COLUMN=filepath
AZURE_SEARCH_TITLE_COLUMN=title
AZURE_SEARCH_URL_COLUMN=url
AZURE_SEARCH_CONVERSATIONS_LOG_INDEX=conversations-log
AZURE_SEARCH_USE_INTEGRATED_VECTORIZATION=false
AZURE_SEARCH_INDEXER_NAME=
AZURE_SEARCH_DATASOURCE_NAME=
# Azure OpenAI for generating the answer and computing the embedding of the documents
AZURE_OPENAI_RESOURCE=your-azureopenai-resource
AZURE_OPENAI_ENDPOINT=https://your-azureopenai-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-azureopenai-apikey
AZURE_OPENAI_MODEL=gpt-4o-mini
AZURE_OPENAI_MODEL_NAME=gpt-4o-mini
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-large
AZURE_OPENAI_TEMPERATURE=0.2
AZURE_OPENAI_TOP_P=1.0
AZURE_OPENAI_MAX_TOKENS=1000
AZURE_OPENAI_STOP_SEQUENCE=
AZURE_OPENAI_SYSTEM_MESSAGE=You are an AI assistant that helps people find information.
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_STREAM=True
# Backend for processing the documents and application logging in the app
AzureWebJobsStorage= # not sure yet if only for local or how to point to prod
#BACKEND_URL=http://localhost:7071
AZURE_BLOB_ACCOUNT_NAME=
AZURE_BLOB_ACCOUNT_KEY=
AZURE_BLOB_CONTAINER_NAME=
DOCUMENT_PROCESSING_QUEUE_NAME= # think not needed after backend is removed
# Azure Form Recognizer for extracting the text from the documents
AZURE_FORM_RECOGNIZER_ENDPOINT=
AZURE_FORM_RECOGNIZER_KEY=
# Azure AI Content Safety for filtering out the inappropriate questions or answers
AZURE_CONTENT_SAFETY_ENDPOINT=
AZURE_CONTENT_SAFETY_KEY=
# Orchestration strategy. Use Azure OpenAI Functions (openai_function), Semantic Kernel (semantic_kernel), LangChain (langchain) or Prompt Flow (prompt_flow) for messages orchestration. If you are using a new model version 0613 select any strategy, if you are using a 0314 model version select "langchain". Note that both `openai_function` and `semantic_kernel` use OpenAI function calling.
ORCHESTRATION_STRATEGY=openai_function
# If selected Prompt Flow as orchestration strategy, please provide the following environment variables. Note that Prompt Flow does not support RBAC authentication currently.
AZURE_ML_WORKSPACE_NAME=
PROMPT_FLOW_DEPLOYMENT_NAME=
PROMPT_FLOW_ENDPOINT_NAME=
#Speech-to-text feature
AZURE_SPEECH_SERVICE_KEY=
AZURE_SPEECH_SERVICE_REGION=
# Auth type environment variables.
# When AZURE_AUTH_TYPE=rbac, please make sure variable USE_KEY_VAULT=false
# When USE_KEY_VAULT=true, please make sure to set AZURE_KEY_VAULT_ENDPOINT
AZURE_AUTH_TYPE=keys
USE_KEY_VAULT=true
AZURE_KEY_VAULT_ENDPOINT=
# Chat conversation type to decide between custom or byod (bring your own data) conversation type
CONVERSATION_FLOW=
# Chat History, Document Chunk, and Vector Store
DATABASE_TYPE=PostgreSQL
AZURE_POSTGRESQL_HOST_NAME= # blank for local dev
AZURE_POSTGRESQL_DATABASE_NAME= # blank for local dev
AZURE_POSTGRESQL_USER= # blank for local dev
# local dev.
POSTGRESQL_HOST=localhost
POSTGRESQL_DB=postgres
POSTGRESQL_USER=postgres
POSTGRESQL_PASSWORD=postgres
AZURE_AUTH_ENABLED=false      # local dev: no key required
LOAD_CONFIG_FROM_BLOB_STORAGE=false
APPLICATIONINSIGHTS_ENABLED=false
#LOGLEVEL=DEBUG

# Vite frontend API base URL
# VITE_BACKEND_URL=http://azure_function:80
# Local development in docker map to localhost instead of container name
VITE_BACKEND_URL=http://localhost:8088
CHAT_HISTORY_ENABLED=true
